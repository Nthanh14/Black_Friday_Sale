# -*- coding: utf-8 -*-
"""Bản sao của Black_Friday_Sale

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CUyG1U5hqeSuB1zO8aFGq1YhjwVn-w-z
"""

from google.colab import files
uploaded = files.upload()

# ĐỌC DỮ LIỆU
import pandas as pd
df = pd.read_csv('/content/Black_Friday_Sale.csv')
#check data
print("\nData information:")
print(df.info())
print("\nData Description:")
print(df.describe())

df['Product_Category_2'] = df['Product_Category_2'].fillna(0)
df['Product_Category_3'] = df['Product_Category_3'].fillna(0)
df = df.drop_duplicates()
print(f"Number of records remaining after prosessing: {len(df)}.")

df['Gender'] = df['Gender'].map({'M': 1, 'F': 0})
age_map = {'0-17': 1, '18-25': 2, '26-35': 3, '36-45': 4, '46-50': 5, '51-55': 6, '55+': 7}
df['Age'] = df['Age'].map(age_map)
df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].replace('4+', 4).astype(int)
df = pd.get_dummies(df, columns=['City_Category'], prefix='City')
print("Null values after preprocessing:")
print(df.isnull().sum())

print("\nSummary Statistics:")
print(df.describe())
print("\nAverage Purchase by Gender:")
print(df.groupby('Gender')['Purchase'].mean())
print("\nAverage Purchase by Age:")
print(df.groupby('Age')['Purchase'].mean())
print("\nTotal Purchase by City Category:")
print(df[['City_A', 'City_B', 'City_C']].multiply(df['Purchase'], axis=0).sum())

import matplotlib.pyplot as plt
import seaborn as sns
# Visualization 1: Bar Chart - Average Purchase by Gender
plt.figure(figsize=(8, 6))
gender_purchase = df.groupby('Gender')['Purchase'].mean()
sns.barplot(x=gender_purchase.index.map({0: 'Female', 1: 'Male'}), y=gender_purchase.values)
plt.title('Average Purchase by Gender')
plt.xlabel('Gender')
plt.ylabel('Average Purchase (K$)')
plt.savefig('gender_purchase.png')
plt.show()

# Visualization 2: Pie Chart - Distribution of customer numbers by Gender
gender_counts = df['Gender'].value_counts().reset_index()
gender_counts.columns = ['Gender', 'Count']
plt.figure(figsize=(8, 6))
plt.pie(gender_counts['Count'], labels=['Female', 'Male'], colors=['pink', 'blue'], autopct='%1.1f%%', startangle=90)
plt.title('Distribution of customer numbers by Gender')
plt.axis('equal')  # Đảm bảo hình tròn
plt.show()

# Visualization 3: Bar Chart - Total Purchase by City Category
plt.figure(figsize=(8, 6))
city_purchase = df[['City_A', 'City_B', 'City_C']].multiply(df['Purchase'], axis=0).sum() / 1000
sns.barplot(x=city_purchase.index, y=city_purchase.values)
plt.title('Total Purchase by City Category')
plt.xlabel('City Category')
plt.ylabel('Total Purchase (K$)')
plt.savefig('city_purchase.png')
plt.show()

# Visualization 4: Pie Chart - Product Category 1 Distribution
plt.figure(figsize=(8, 8))
product_cat1_counts = df['Product_Category_1'].value_counts()
# Filter categories with significant counts (>5000)
product_cat1_counts = product_cat1_counts[product_cat1_counts > 5000]
plt.pie(product_cat1_counts, labels=[f'Category {x}' for x in product_cat1_counts.index], autopct='%1.1f%%', startangle=140)
plt.title('Product Category 1 Distribution')
plt.savefig('product_cat1_distribution.png')
plt.show()

# Visualization 5: Line Chart - Total Purchase by Stay in Current City
plt.figure(figsize=(8, 6))
stay_purchase = df.groupby('Stay_In_Current_City_Years')['Purchase'].sum() / 1000
plt.plot(stay_purchase.index, stay_purchase.values, marker='o')
plt.title('Total Purchase by Years in Current City')
plt.xlabel('Years in Current City')
plt.ylabel('Total Purchase (K$)')
plt.savefig('stay_purchase.png')
plt.show()

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
# Step 5: Model Training
# Select features for clustering
features = ['Gender', 'Age', 'Occupation', 'Stay_In_Current_City_Years',
            'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3',
            'Purchase', 'City_A', 'City_B', 'City_C']
X = df[features]
# Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# Apply KMeans to cluster customers
# Using k=3 as an example (adjust based on elbow method if needed)
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(X_scaled)
# Display the first few rows with cluster assignments
print("First few rows with cluster assignments:")
print(df[['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation',
          'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',
          'Product_Category_2', 'Product_Category_3', 'Purchase', 'Cluster']].head())

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
# Prepare the data for modeling
X = df.drop(['Purchase', 'User_ID', 'Product_ID'], axis=1)
y = df['Purchase']
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Initialize and train the linear regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = lr_model.predict(X_test)
# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")
print(f"R-squared: {r2:.4f}")
print(f"Mean Absolute Error: {mae:.4f}")

wcss = kmeans.inertia_
wcss_adjusted = wcss * 0.001
print(f"WCSS (Sum of squares within cluster): {wcss_adjusted:.2f}")